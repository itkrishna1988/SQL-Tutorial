@startuml
title DocD System Sequence Diagram for Event Tracking

actor LOB as C
participant "DC A3 L2 W9" as ComposeApps
participant "Q9" as Q9
participant "1MCS" as 1MCS
participant "DocD" as DOCD
participant "ICMP" as ICMP
participant "ANG" as ANG
participant "PDH" as PDH
participant "RRD Internal IWCO Covius" as PV
participant "SendSuit" as SendSuit
participant "USPS" as USPS

== Print Delivery Workflow==
C -> ComposeApps: Print request
C -> Q9: Print request

alt Batch Composed (DC, A3, L2, W9, ComposeApps)
    ComposeApps -[#FF4500]-->DOCD: Initiated & Composed
else Kafka Composed(Q9)
     1MCS -[#0000FF]-> DOCD: Initiated (docd.wfevents.initiated)
     Q9 -[#0000FF]-> DOCD: Composed (docd.wfevents.composed)
end
 ICMP -[#0000FF]-> DOCD: Archived
 PDH -[#FF4500]-->DOCD: Sent-to-pv
 PDH -[#FF4500]-->PV: AFP Print file & IDX
 PV -[#FF4500]-->PDH: Received & Reconciled
 PDH -[#FF4500]-->DOCD: Received & Reconciled
 PV -[#FF4500]-->PDH: Processed, Printed, Inserted & Mailed
 PDH -[#FF4500]-->DOCD: Processed, Printed, Inserted & Mailed
 PV -[#FF4500]-->PDH: Invoiced & Taxed
 PDH -[#FF4500]-->DOCD: Invoiced & Taxed


== Digital Delivery Workflow ==
C -> 1MCS: Emailed Request

    1MCS-[#0000FF]-> DOCD: Initiated (docd.wfevents.initiated)
    1MCS -[#0000FF]-> DOCD: Composed (docd.wfevents.initiated)
    1MCS -[#0000FF]-> ANG: EMAIL request
    ANG-[#0000FF]-> DOCD: EMAILED, INBOX, PUSH, SMS (ci.alerts.feedback)

== Handling Email Bounceback and Triggering Print Communication ==
alt Email Bounceback
    ANG -[#FF0000]-> 1MCS: Email Bounceback Notification
    1MCS -[#FF0000]-> Q9: Email Failed, Trigger Print Communication
    Q9 -[#FF4500]-> PDH: Batch New Print Composed Message
    PDH -[#FF4500]-> DOCD: Sent-to-pv for Printing
    PDH -[#FF4500]-> PV: AFP Print file & IDX
    PV -[#FF4500]-> PDH: Received & Reconciled
    PDH -[#FF4500]-> DOCD: Received & Reconciled
    PV -[#FF4500]-> PDH: Processed, Printed, Inserted & Mailed
    PDH -[#FF4500]-> DOCD: Processed, Printed, Inserted & Mailed
end															  
	
== Postal Events via SendSuit ==
USPS -> SendSuit: Download post office data
SendSuit -> DOCD: Outbound, Inbound, Address Correction

@endumlThanks for the clarification! Based on the images you uploaded, here's a summary of the **DocD App Delivery Highlights**:

---

### **DocD App Delivery Highlights**

1. **Auto ILD Autopay Setup Emails – Reconciliation**  
   - Automate the generation and archiving of autopay confirmation emails.
   - Ensure that bounce-back emails are identified, reconciled, and appropriately handled.
   
2. **Build & Migrate SBL Products to New Application Platform**  
   - Migration of SBL products to a new modernized platform for handling loan-related communications, with a focus on simplifying processes for small businesses.

3. **Auto Disaster Deferment Email – Compliance**  
   - Automation of the disaster deferment email process, including archiving and delivery.
   - Ensuring compliance with regulatory requirements through archiving and reconciliation.

4. **CAS Create Branch USPS Disclosure Mailing**  
   - USPS mailing for multiple recipients with branch support for both physical and digital disclosures.
   - Compliance with USPS regulations for multiple services.

5. **Cross-Channel Banker Platform Integration**  
   - Consolidating data feed systems for customer communication from multiple sources into a unified platform.
   - Aiming for streamlined communication and faster processing across different channels, including print and email.

6. **POS Loan Servicing for New Products**  
   - New POS loan products will be integrated into the DocD system, focusing on automating customer communication and ensuring that both current and prospective customers receive consistent service.

---

These highlights reflect a focus on automating email, reconciliation processes, compliance, and expanding the platform to integrate new products and USPS services. Let me know if you'd like any part expanded or further details!

a
Sure! Here's a user story for the **DOCd Home Page** in Confluence:

---

### **User Story 1: Create DOCd Application Home Page**

**Title**: Create a DOCd application homepage in Confluence for information dissemination and system overview.

---

#### **As a:**
Product Owner / Team Member / User of the DOCd system

#### **I want to:**
Access a centralized, informative homepage in Confluence that provides all essential information about the DOCd application.

#### **So that:**
- I can understand how DOCd works, its key features, system architecture, workflows, and compliance processes.
- I can easily find documentation, workflows, and diagrams relevant to DOCd.
- Team members, stakeholders, and other users can access a single source of truth regarding the DOCd system.

---

### **Acceptance Criteria:**

1. **Overview Section**:
   - The DOCd home page should contain a high-level overview of the application, its purpose, and what problem it solves (event tracking, communication lifecycle management, and compliance).

2. **Key Features Section**:
   - List key features such as event tracking, multi-channel support, batch and stream processing, archiving, integration with vendors (USPS), bounce-back handling, etc.

3. **System Architecture Section**:
   - Provide a high-level system architecture overview in the form of a diagram (using Confluence’s built-in draw.io integration) showing how DOCd interacts with other systems (LOB, 1MCS, ComposeApps, USPS, etc.).

4. **Workflow Diagrams**:
   - Include at least two diagrams showcasing different workflows (e.g., digital email workflow and print communication workflow). The diagrams must be clear and explain how DOCd processes different communication channels.

5. **Event Status Definitions**:
   - Include a section that defines key event statuses such as Initiated, Composed, Emailed, Mailed, Archived, Failed, etc.

6. **Integration Points**:
   - Explain how DOCd integrates with internal systems (e.g., 1MCS, ICMP, ANG) and external vendors (e.g., USPS, IWCO) to facilitate communication.

7. **Failure Handling (Bounce-back)**:
   - Add a section that explains the bounce-back handling process and how DOCd transitions failed digital communications to the print channel.

8. **Compliance and Archiving**:
   - A section detailing how DOCd complies with regulatory requirements by archiving communication events, providing audit trails, and enforcing retention policies.

9. **FAQs Section**:
   - Provide a Frequently Asked Questions section to answer common user inquiries, such as how to initiate communication, track statuses, and handle bounce-back events.

10. **Contact Information**:
    - Provide up-to-date contact information for support, escalation, and other queries.

11. **Resources and Documentation Links**:
    - Ensure there are links to relevant resources, including user guides, technical documentation, API docs, and architecture diagrams.

---

### **Additional Notes:**

- The homepage should be visually structured for easy navigation, with each section clearly labeled.
- The page should be kept up to date with the latest system changes and workflow modifications.
- Diagrams should be easy to read, and interactive where possible (e.g., embedding Confluence diagrams).
- Provide quick access to resources such as documentation links and API references.
- Consider adding a version history to the homepage to track updates.

---

### **Story Points/Complexity:**
8 (Moderate complexity, requiring diagrams, collaboration across teams, and detailed documentation)

---

### **Priority:**
High

---

By completing this user story, you’ll provide users, stakeholders, and team members with a comprehensive, easy-to-navigate page that offers all essential information about the DOCd Year-End Performance Review

Employee Name: [Your Name]

Position: DocD Developer

Team/Project: DocD, Customer Confidential Program (CCP), Wells Fargo

1. Overview of Accomplishments

Over the past year, I have successfully contributed to the success of various projects, particularly in the DocD and Customer Confidential Program (CCP) teams at Wells Fargo. I played a crucial role in developing, testing, and improving the DocD application, focusing on Kafka-based event-driven architectures, data management processes, and SQL optimizations. The following is a detailed account of my contributions and accomplishments:

2. Key Responsibilities and Deliverables

	1.	Kafka Event Schema Design & Implementation:
	•	Achievement: I defined and implemented a Kafka event schema for producing event statuses for DocD. This schema captured the lifecycle events of documents, such as initiation, composition, printing, mailing, and archiving. I ensured that the schema was both flexible and scalable to accommodate various lifecycle event types.
	•	Impact: Improved the visibility of document events in the system, making it easier for teams to track document status and event data, providing a robust framework for LOB (Line of Business) applications to consume.
	2.	Batchless Process for Package Tracking:
	•	Achievement: I modified multiple stored procedures to support the batchless process for tracking packages. These changes enabled the system to handle package-only processes while maintaining performance and data integrity.
	•	Impact: Enhanced the DocD application’s ability to track package events efficiently, supporting better user experiences by allowing users to view events related to package processes such as recomposed, inbox, printed, and emailed events.
	3.	Optimized SQL Data Deletion Process:
	•	Achievement: I implemented an optimized data deletion process for Kafka Consumer and Producer tables, which had grown significantly. By introducing a batch deletion mechanism that deleted 100,000 records at a time, I ensured the process would not overwhelm SQL Server logs or impact performance.
	•	Impact: Reduced table sizes and optimized server performance while maintaining data accuracy and ensuring no system slowdowns during the deletion process.
	4.	Improvement of Monthly Invoice Exceptions:
	•	Achievement: I investigated and resolved an issue where the DocD UI was incorrectly flagging all invoices as exceptions due to mismatched billing codes. I ensured accurate exception logging in the ReconExceptions table and corrected historical data to reflect the right invoice statuses.
	•	Impact: Provided more accurate financial reporting and improved the team’s ability to track genuine invoice exceptions, minimizing the time spent resolving false positives.
	5.	UI and Procedure Modifications for Package Events:
	•	Achievement: During UAT testing, I proactively identified and addressed issues in UI procedures, such as docd-GET-PackageSearchData and docd-GET-PackageEventData, ensuring the proper handling of recomposed packages and document data at various lifecycle stages.
	•	Impact: The UI improvements and back-end adjustments enhanced the end-user experience, streamlining the tracking and display of document events and statuses, improving the product’s reliability.

3. Collaboration and Teamwork

	•	Cross-Functional Collaboration: Throughout the year, I worked closely with various teams including QA, UAT, and business stakeholders. I took ownership of cross-team communication, ensuring that the Kafka events and related stored procedures met all requirements.
	•	Mentorship: I provided guidance to team members during the integration of Kafka streams and batchless processing. This not only helped the team meet deadlines but also improved the team’s overall technical capabilities.

4. Technical Innovation

	•	Automation of Testing Processes: I led efforts to automate critical and smoke tests for the DocD system, using frameworks that ensured the system could be tested thoroughly and efficiently before deployment. These automated tests contributed to more reliable deployments and significantly reduced time spent on manual testing.
	•	Logging and Error Handling Improvements: I improved the logging mechanisms across various systems, ensuring that we could quickly identify and address errors in real time. This led to faster issue resolution and more stable application performance.

5. Problem Solving and Initiative

I consistently demonstrated initiative in resolving complex problems before they became critical. For example, I identified the mismatched billing code issue in monthly invoicing, which would have caused significant downstream financial discrepancies had it not been addressed. My approach to problem-solving involved both technical fixes and collaboration with the relevant stakeholders to ensure long-term solutions were implemented.

6. Areas of Growth and Development

	•	Learning & Development: Over the year, I dedicated time to enhance my knowledge of event-driven architectures, especially Kafka, which was essential for the DocD application. I also focused on improving my SQL and database management skills to ensure the systems I worked on remained performant.
	•	Taking Initiative: I proactively took on the responsibility of managing unassigned tasks and system improvements without waiting for user stories. This demonstrated my commitment to the team’s success and my initiative to improve processes wherever possible.

7. Goals for the Upcoming Year

	•	Further Optimization of Kafka Processes: I plan to continue improving the Kafka event streams, with a focus on optimizing throughput and minimizing latency in event consumption.
	•	Advanced Automation: I aim to expand the scope of automation within the DocD system to include regression and performance testing, ensuring that the system is tested in real-world scenarios before production deployment.
	•	Mentorship: I plan to take on more mentorship roles within the team, sharing my expertise in Kafka, SQL optimization, and testing automation with newer team members to ensure the team is equipped with the skills to handle complex challenges.

8. Conclusion

In summary, this year has been incredibly productive and impactful. I have contributed to key projects, optimized core processes, and made meaningful improvements to the DocD system. I am confident that my work has positively influenced the team and improved the system’s functionality and performance. I look forward to continuing to drive success and innovation in the coming year.

Here’s a draft of your year-end performance review based on the previous work you’ve shared:

Year-End Performance Review

Name: [Your Name]
Position: [Your Position]
Year: 2024

1. Overview of Key Accomplishments:

Throughout the year, I have worked diligently across multiple teams and projects, ensuring effective communication, execution, and delivery of key objectives. Some notable accomplishments include:

	•	Project Leadership: Led significant tasks for the DocD application, including working on the integration of various components such as Kafka topics, event tracking, and aligning it with Shoreview production requirements. I ensured smooth execution and transitions during our production and testing phases, addressing issues like policy failures and patching activities.
	•	Collaborative Problem Solving: Demonstrated strong collaboration with teams like ASER, BO, and Lending Grid to solve integration and data migration challenges. For example, I coordinated with multiple teams to address issues in mapping fields for archived events and solved discrepancies in event data.
	•	Process Optimization: Implemented enhancements to streamline existing processes, such as refining how DocD processes Archived events. This helped avoid duplicate event processing issues and improved overall system efficiency.
	•	Documentation and Communication: Maintained detailed communication with key stakeholders to ensure clarity on project goals, progress, and roadblocks. This included simplifying complex scenarios (like bounce-back events and archived messages) into actionable insights for different teams.
	•	Release Management: Played a key role in overseeing code merges and deployments for the August and September releases. I ensured that there were no conflicts between overlapping releases and that UAT deployments went smoothly.
	•	Support for Teams: Actively supported various cross-functional teams, providing detailed analysis and ensuring proper onboarding processes for data access requirements. I worked closely with the platform team to provide secure and efficient access, as well as supported troubleshooting and patching tasks.

2. Strengths Demonstrated:

	•	Communication: Demonstrated clear, consistent communication with team members and stakeholders, ensuring that expectations were met, and any ambiguities were addressed swiftly.
	•	Attention to Detail: Ensured precision in tasks related to data mapping, system requirements, and testing, especially in complex processes like event archiving and data migrations.
	•	Problem-Solving: Showcased strong analytical skills when resolving issues related to database access, event schema changes, and production discrepancies.
	•	Leadership: Took proactive steps to manage overlapping releases and provided clear direction to ensure efficient code merging, deployment, and project completion.

3. Areas of Improvement:

While I have made notable contributions this year, there are a few areas where I can further develop:

	•	Advanced Technical Skills: I aim to enhance my SQL Server and SSIS development skills to lead more technically complex projects independently.
	•	Project Prioritization: With many tasks running simultaneously, I will focus on improving project prioritization and time management to streamline multiple concurrent responsibilities.

4. Goals for the Upcoming Year:

	•	Develop Deeper Technical Expertise: Focus on strengthening my expertise in SQL Server development, SSIS, and database performance optimization to contribute more effectively to system-level improvements.
	•	Process Automation: Work towards automating some of the manual processes in event tracking and reporting to further enhance efficiency and reduce dependency on human intervention.
	•	Cross-functional Collaboration: Continue to improve collaborative efforts with cross-functional teams to ensure smoother, quicker decision-making and project delivery.

In summary, this year has been an opportunity to deliver on important projects and collaborate across various teams and functions. I look forward to continuing this momentum and achieving even greater results in the upcoming year.


Based on the context I have, here’s a draft of your year-end performance review for your appraisal:

Year-End Performance Review

Name: [Your Name]
Role: [Your Role]
Department: [Your Department]
Date: [Date of Submission]

Key Achievements:

	1.	DocD Application Development and Support:
	•	Played a key role in the development, implementation, and optimization of the DocD Application at Wells Fargo, an event-driven system used to manage the customer communication lifecycle, including email, print, and SMS communications.
	•	Architected and improved Kafka Stream integrations to handle high-throughput events like initiated, composed, emailed, and print communications from various applications (DC, A3, L2, W9, 1MCS, ANG, etc.).
	•	Developed a robust process for consuming print-initiated events through Kafka Topics and batch files, optimizing the flow for print vendor processing and postal events.
	2.	Performance and Process Optimization:
	•	Optimized existing stored procedures in SQL Server by consolidating MERGE statements into reusable code modules. This helped reduce redundancy, improved maintainability, and significantly boosted query performance.
	•	Enhanced system performance by designing efficient data archiving strategies in the DocD application, specifically around email and print communications.
	•	Worked on error-handling mechanisms, specifically implementing a process to reroute email bounce-backs to print communication, ensuring business continuity in customer communication.
	3.	Technical Expertise and Contributions:
	•	Deepened knowledge of technologies like SQL Server Enterprise Edition, Kafka, Avro Schemas, and Confluence, contributing to the overall system architecture.
	•	Created architecture diagrams and UML sequence diagrams for the DocD application to map out the communication flows between different systems, improving cross-team understanding and alignment.
	•	Actively contributed to the automation of documentation on Confluence, making information more accessible and streamlined for other team members.
	4.	Collaboration and Leadership:
	•	Actively collaborated with multiple teams and stakeholders, including development teams working on DC, A3, L2, W9, and Q9 applications, as well as external vendors for print and postal services.
	•	Demonstrated strong project management skills by consistently meeting deadlines, particularly during high-priority initiatives, ensuring that the DocD application functioned seamlessly in production environments.
	•	Played a pivotal role in troubleshooting critical incidents, including addressing database deadlocks and optimizing SQL queries to ensure minimal downtime.
	5.	Initiatives and Innovations:
	•	Proactively worked on migrating various batch processes to more efficient Kafka Stream-based processing, reducing processing times and system load.
	•	Took the initiative to redesign the DocD homepage in Confluence, enhancing internal documentation and improving user experience for team members and stakeholders.

Areas for Improvement:

	•	Continue to enhance skills in cloud-based technologies (e.g., MongoDB licensing and cloud deployment strategies) to broaden the scope of solutions provided to the team.
	•	Explore opportunities for more automation in repetitive tasks, especially in monitoring and error recovery for batch and stream communications.

Goals for the Next Year:

	1.	Further improve system performance by implementing advanced indexing strategies and SQL query optimizations.
	2.	Lead the initiative to scale the DocD system for larger data volumes, possibly leveraging cloud-native technologies.
	3.	Take ownership of cross-functional training sessions to help onboard new team members to the DocD system and related technologies.

Closing Thoughts:

This year, I have made significant contributions to the success of the DocD application and its seamless integration with other systems. I look forward to building on these achievements, continuing to deliver high-quality work, and driving innovative solutions in the upcoming year.

As a DocD application lead and lead software engineer LSE I done this work  I will share my goals please help me to write year end self To create a DOCd home page in Confluence, you’ll want to include key details that provide a clear, informative overview of the system for users, stakeholders, and team members. Here’s a guide on what details you can mention and how to structure the content for the DOCd home page:

DOCd Application Home Page

1. Introduction/Overview

Provide a brief introduction to the DOCd application. Explain its purpose and high-level functionality.

Example:

DOCd Overview:

DOCd is an event-driven system designed to archive and track customer communication lifecycle metadata across multiple channels (email, SMS, print, etc.). It ensures regulatory compliance, accurate archiving, and seamless integration with different business applications like ComposeApps, ICMP, and external partners (USPS, IWCO).

DOCd plays a critical role in capturing the status of events, managing both digital and physical delivery channels, and providing real-time status updates for various lifecycle events such as initiated, composed, printed, emailed, and mailed.

2. Key Features

Highlight the main features and functionalities that DOCd provides. This section should showcase the system’s strengths.

Example:

Key Features:

	•	Event Tracking: Track the entire lifecycle of customer communication from initiation to delivery.
	•	Batch and Stream Processing: Supports both batch and real-time data processing for communication events.
	•	Archival: Archives communication events, metadata, and relevant documents for compliance.
	•	Multi-Channel Support: Handles digital (email, SMS) and physical (print, postal mail) communication channels.
	•	Integration: Integrates seamlessly with other Wells Fargo systems, external vendors (e.g., USPS), and delivery platforms.
	•	Bounce-back Handling: Automatically processes bounce-backs and failed emails, converting them to print communication workflows.

3. System Architecture

Provide a high-level overview of the system architecture. You can use diagrams or bullet points to explain how the components are connected.

Example:

System Architecture:

DOCd integrates various systems and vendors to ensure smooth communication workflows. Key components include:

	•	LOB (Line of Business): Initiates communication requests.
	•	ComposeApps/Q9: Composes print/digital content and initiates event tracking.
	•	1MCS: Manages the workflow and integration with external systems (ANG, USPS).
	•	PDH (Print Data Hub): Manages the printing process and reconciliation with external vendors.
	•	ANG (Email & SMS Service): Sends email and SMS notifications and manages delivery failures.
	•	ICMP: Archives documents and metadata for compliance and regulatory purposes.

![System Architecture Diagram] (Insert architecture diagram or Confluence draw.io diagram link here)

4. Workflow Diagrams

If relevant, include diagrams to show the communication workflow. You can provide separate workflows for batch communication, real-time streaming, or digital and physical workflows.

Example:

Communication Workflows:

	1.	Batch Communication Workflow:
	•	LOB initiates a request → ComposeApps prepares content → Q9 batches the request → PDH handles printing and delivery.
	2.	Digital Communication Workflow:
	•	LOB sends a request → 1MCS handles initiation and composition → ANG sends emails/SMS notifications → DOCD logs status.

(Embed diagrams using draw.io in Confluence for clarity.)

5. Event Status Definitions

Explain the different event statuses that DOCd manages. This will help users understand the system’s terminology and processes.

Example:

Event Status Definitions:

	•	Initiated: Communication request is initiated but not yet processed.
	•	Composed: Content has been prepared and is ready for delivery.
	•	Emailed: Communication has been sent via email.
	•	Mailed: Physical communication has been printed and mailed.
	•	Archived: Communication event and associated content have been archived for compliance.
	•	Failed: Email or SMS delivery failed and requires further action (e.g., convert to print communication).

6. Integration Points

Outline the key integration points with other systems and external vendors.

Example:

Integration Points:

	•	1MCS: Handles workflow management and orchestrates communication across systems.
	•	USPS: Manages the postal service delivery of printed communications.
	•	SendSuit: Downloads post office data and handles address corrections.
	•	ICMP: Archives documents and event data for compliance and retrieval.
	•	ANG: Manages email and SMS delivery for digital communication channels.

7. Failure Handling (Bounce-back Process)

Provide details about how the system handles communication failures such as email bounce-backs and how it transitions to print communication.

Example:

Bounce-back Handling:

If an email fails or bounces back, DOCd automatically transitions the communication to the print workflow. The steps involved are:

	1.	Bounce-back Detection: ANG identifies the email bounce-back and sends failure data to 1MCS.
	2.	Transition to Print: 1MCS relays the data to Q9 for batch processing.
	3.	Print Workflow: Q9 batches the request and sends it to PDH for printing and mailing.
	4.	Tracking: The status of the print communication is updated in DOCd, ensuring end-to-end traceability.

8. Compliance and Archiving

Provide details on how DOCd ensures compliance with regulations and manages archival processes.

Example:

Compliance and Archiving:

	•	Document Archival: All communication events and metadata are archived in ICMP for regulatory compliance.
	•	Audit Trails: DOCd provides complete audit trails for each communication event, ensuring accountability.
	•	Retention Policy: Data retention policies are enforced based on business requirements and regulatory needs.

9. Frequently Asked Questions (FAQs)

Provide a section for common questions that users may have.

Example:

FAQs:

	•	Q: How do I initiate a new communication request?
A: Use the LOB portal or API to submit communication requests to ComposeApps or 1MCS.
	•	Q: How do I track the status of a communication?
A: The DOCd dashboard allows you to track communication statuses like Initiated, Composed, Emailed, Mailed, and Archived.
	•	Q: What happens if an email fails to deliver?
A: The system automatically transitions the communication to print if an email bounces back.

10. Contact Information

Provide relevant contact details for support, escalation, or queries.

Example:

Contact Information:

	•	Support Team: support@docd.example.com
	•	Escalation: escalation@docd.example.com
	•	Product Owner: [Name] (email@domain.com)

11. Resources and Documentation

Link to any relevant resources or documentation, such as technical specs, API docs, or user manuals.

Example:

Resources:

	•	User Guide
	•	Technical Architecture
	•	API Documentation

DocD built a robust framework for digital failure handling, enabling efficient tracking and resolution of bounce-back events across customer communication lifecycles. Its reliable metadata-driven approach ensures seamless recovery, and with its scalable architecture, more lines of business are leveraging DocD to manage bounce-back flows and improve operational efficiency.

 

With this structure, you’ll provide a comprehensive and user-friendly DOCd homepage in Confluence. Adjust the details based on your specific DOCd system’s needs and configurations.DocD built a robust framework for handling Statement Ready Notifications (SRN), ensuring timely and accurate communication to customers when their statements are available online for viewing. By leveraging its metadata-driven system, DocD ensures seamless notification delivery and quick resolution of any issues. Its scalable and reliable architecture has enabled more lines of business to adopt DocD for managing SRN processes efficiently.

Epic Title:

DocD Application Data Center Migration & Platform Modernization

⸻

Epic Description:

As part of infrastructure modernization and strategic alignment with enterprise standards, the DocD application will undergo a comprehensive data center migration. This initiative includes:
	•	SQL Server Upgrade: Migrating from SQL Server 2017 to SQL Server 2022
	•	Windows OS Upgrade: Transitioning from Windows Server 2016 to the latest approved OS version
	•	Data Storage Migration: Moving NAS (Network Attached Storage) to new data center storage
	•	File Transfer Modernization: Migrating NDM (Network Data Mover) processes to the new environment
	•	Data Center Move: Shifting compute and storage footprint to the newly provisioned data center, ensuring high availability and resiliency.

This Epic will ensure DocD meets performance, scalability, and security standards required for long-term sustainability and compliance.

⸻

Scope of Work:
	1.	SQL Server Modernization
	•	Build SQL Server 2022 (FCI + Always On AG) in the new data center
	•	Migrate all databases from SQL Server 2017 to SQL Server 2022
	•	Validate Always On Availability Groups with automatic failover and read-intent routing
	2.	Windows Upgrade
	•	Provision application and database servers with latest approved Windows OS
	•	Perform compatibility testing and remediation as needed
	3.	NAS Migration
	•	Identify and copy all DocD-related NAS data to new storage
	•	Update all file paths in applications and ETL jobs
	4.	NDM Migration
	•	Reconfigure all NDM endpoints and channels in the new environment
	•	Coordinate with upstream/downstream partners for data movement validation
	5.	Testing & Cutover
	•	Complete functional, performance, integration, and DR testing
	•	Plan and execute final cutover with rollback plan
	6.	Documentation & Compliance
	•	Update architecture diagrams, SOPs, and control documents
	•	Ensure compliance with Cyber, SDLC, and Change Management policies

⸻

Benefits:
	•	Improved performance and security with SQL 2022 and latest OS
	•	Aligned with enterprise standards for platform lifecycle
	•	Enhanced availability and disaster recovery capabilities
	•	Reduction in legacy tech debt

⸻

Stakeholders:
	•	App Owner / Tech Lead: Krishna Reddy Lankireddy
	•	DBA Team
	•	Infrastructure & Storage Team
	•	Information Security
	•	Business Stakeholders
	•	NDM Coordination Team

⸻

Target Completion: Q3 2025

Would you like a JIRA-style breakdown with epics/stories/tasks as well?


h2. Database Migration – Detailed Steps

The following steps outline the end-to-end process for SQL Server 2017 → 2022 migration in NGDC:

# *Onboard Request*  
  * Submit migration request in ServiceNow/Jira for NGDC DB onboarding  
  * Capture application details, DB size, SLAs, RTO/RPO requirements  

# *Servers Build*  
  * Provision SQL 2022 servers in NGDC (Dev, IST, UAT, Prod)  
  * Configure storage (NAS/SAN) and networking  

# *Servers Validation*  
  * Validate SQL version, patches, collation, and default settings  
  * Validate connectivity from app servers and batch servers  
  * Security baseline validation (TLS, certificates, firewall rules)  

# *Logins Synchronization*  
  * Sync SQL logins, users, and permissions from heritage environment  
  * Validate orphaned users and fix mappings  

# *AG Creation*  
  * Configure Always On Availability Group with replicas (Virginia ↔ Texas)  
  * Validate synchronous commit between PD1/PF1 and PM1/PS1 pairs  
  * Configure read-only routing  

# *Database Restore*  
  * Restore databases from heritage SQL 2017 to SQL 2022 NGDC servers  
  * Apply post-restore steps (permissions, jobs, linked servers, synonyms)  

# *AMA Workflows (for AG replicas switchover)*  
  * Automate replica failover/switchover using AMA workflows  
  * Validate role changes and listener availability  

# *Onboard to Observability*  
  * Integrate with AppDynamics for performance monitoring  
  * Enable Grafana dashboards for DB health & latency metrics  

# *Onboard to Liquibase & Harness*  
  * Setup DB schema change automation using Liquibase  
  * Integrate with Harness pipelines for CI/CD deployments  

# *Create Files & Streams Sync Pipelines*  
  * Setup sync pipelines between Heritage DC and NGDC for:  
   ** Files (via NDM/Robocopy/SnapMirror)  
   ** Kafka/Streams pipelines for messaging  

# *Update CNAMEs*  
  * Update CNAME records for DB listeners in *Dev, IST, UAT*  

# *Update Connection Strings*  
  * Update application UI and ETL connection strings in *Dev, IST, UAT*  
  * Validate with smoke tests  

# *Cutover Dev*  
  * Switch Dev applications to NGDC DB  
  * Validate app functionality and DB workload  

# *Cutover IST*  
  * Switch IST environment to NGDC DB  
  * Validate Autosys, SSIS, NDM, and NAS dependencies  

# *Cutover UAT*  
  * Switch UAT environment to NGDC DB  
  * Run end-to-end testing with business users  
  * Capture UAT signoff  

# *Final Prod Parallel Run*  
  * Run heritage SQL 2017 and NGDC SQL 2022 in parallel  
  * Compare workloads, validate replication, latency, and jobs  

# *Final Production Cutover*  
  * Switch Production workloads to NGDC SQL 2022  
  * Disable heritage SQL 2017 DBs post-validation  
  * Update monitoring, backups, and DR runbooks  




===============================


h1. NGDC Migration Program

This page captures the *Next-Gen Data Center (NGDC) Migration* activities covering:
* Database Deployment & SQL Server Upgrade (2017 → 2022)
* NAS Migration
* SSIS Package Migration
* Autosys Migration
* NDM Migration

The objective is to ensure *seamless migration* to the new infra with *minimal downtime* and *clear visibility* across all phases (Dev → IST → UAT → Prod).

---

h2. 1. New Infrastructure Details

* *SQL Server Version:* 2022 Enterprise Edition
* *Always On Availability Group (AG):* Multi-DC (Virginia + Texas)
* *Primary Site:* Virginia (PD1 & PF1)
* *DR Site:* Texas (PM1 & PS1)
* *Storage:* NAS Migration from legacy SAN to enterprise NAS (NetApp / Dell EMC)
* *Job Scheduler:* Migration from legacy Autosys to NGDC Autosys platform
* *File Transfers:* Migration from legacy NDM to NGDC NDM cluster
* *ETL Tools:* Migration from SSIS 2017 to SSIS 2022 execution framework

---

h2. 2. Workstreams

h3. 2.1 Database Deployment (SQL Server 2017 → 2022)
* Environment provisioning (Dev, IST, UAT, Prod)
* Database backups & restores
* Availability Group configuration (multi-site sync/async)
* Read-only routing configuration
* Cutover & Post-Migration validation

h3. 2.2 NAS Migration
* Inventory of applications using legacy NAS
* Data copy strategy (rsync/robocopy/SnapMirror)
* Cutover planning (low downtime migration)
* Post-validation (MD5 checksum, application validation)

h3. 2.3 SSIS Migration
* Inventory of SSIS packages
* Deploy to SSISDB (SQL 2022)
* Validate connections, credentials, and security
* Performance benchmarking in IST/UAT
* Production cutover with rollback plan

h3. 2.4 Autosys Migration
* Job inventory extraction (from legacy Autosys)
* Job definition migration to NGDC Autosys
* Dry-run in Dev/IST
* Parallel run validation in UAT
* Production switchover

h3. 2.5 NDM Migration
* File transfer flow analysis
* Update endpoints in NGDC NDM cluster
* Parallel run for critical flows
* Performance/throughput testing
* Production cutover with rollback

---

h2. 3. Migration Plan & Timelines

|| Phase || Activities || Timeline || Owner || Status ||
| *Dev* | Provision infra, baseline deployments, connectivity validation | Week 1-2 | Infra + DB Team | {status:complete} |
| *IST* | SQL deployment, SSIS package migration, Autosys job migration dry-run | Week 3-4 | DB + App Teams | {status:in-progress} |
| *UAT* | End-to-end testing (DB, NAS, SSIS, Autosys, NDM) with business sign-off | Week 5-6 | App + Business Teams | {status:planned} |
| *Prod* | Production cutover (phased migration over weekends) | Week 7-8 | Infra + App Teams | {status:planned} |

---

h2. 4. WIP Tracker

|| Task || Description || Owner || Status || ETA ||
| SQL Server Migration (2017 → 2022) | DB deployments in Dev & IST | DBA Team | {status:complete} | – |
| SSIS Migration | Package migration & validation | ETL Team | {status:in-progress} | 09-Sep |
| Autosys Migration | Job conversion & testing | Scheduling Team | {status:planned} | 20-Sep |
| NDM Migration | File transfer validation | Infra Team | {status:planned} | 25-Sep |
| NAS Migration | Data cutover to NGDC NAS | Storage Team | {status:planned} | 30-Sep |

---

h2. 5. AVI Updates

* *Avi Load Balancer* will be updated for:
** SQL Read/Write Listener (docd-gob-dbw)
** SSIS package execution endpoints
** Autosys job schedulers
** NDM transfer endpoints
* Change tickets raised:
** *CHG123456* – AVI updates in IST
** *CHG123789* – AVI updates in Prod

---

h2. 6. Risks & Mitigations

|| Risk || Impact || Mitigation ||
| Cross-state latency during read routing | Performance degradation | Prioritize local sync replica for read-only routing |
| SSIS package connection failures | Job failures post-migration | Validate all connection managers before cutover |
| Autosys job dependency mismatches | Failed job runs | Dry-run in IST & UAT with parallel execution |
| Large NAS data cutover window | Downtime for apps | Use SnapMirror + incremental sync approach |

---

h2. 7. Approvals

* *DB Migration:* Approved by DBA Lead {status:complete}
* *NAS Migration:* Storage Team Signoff {status:planned}
* *SSIS Migration:* ETL Team Signoff {status:in-progress}
* *Autosys Migration:* Scheduling Lead {status:planned}
* *NDM Migration:* Infra Lead {status:planned}



h1. DOCD NGDC Migration Plan

This page captures the end-to-end NGDC migrations for DOCD across five components:
* Database (SQL Server 2017 → 2022)
* SSIS
* NAS
* Autosys
* NDM

h2. 1) Program Overview
* Goal: Seamless migration to NGDC with minimal downtime and clear rollout across DEV → IST → UAT → PROD.
* Tracking: Enterprise Agile Jira (QGJK-34xxx series)
* Observability: AppDynamics, Grafana
* Change Mgmt: ServiceNow CHG tickets per environment & component

h2. 2) Master Timeline (All Components)

|| Environment || Planned Cutover || Status || Notes ||
| DEV | <add date> | {status:in-progress} | Smoke tests + connectivity |
| IST | <add date> | {status:planned} | Middleware alignment |
| UAT | <add date> | {status:planned} | Business signoff |
| PROD (Parallel) | <add date> | {status:planned} | Read-only checks, jobs |
| PROD (Final) | <add date> | {status:planned} | Freeze + cutover weekend |

----

{expand:title=Component A — Database Migration (SQL Server 2017 → 2022)}
h3. A.1 Infrastructure Grid (Latest)

|| Environment || Database Instance || Servers || AG Name || DB Read-only Connection || DB Read/Write Connection || Data Center ||
| DEV | dds1356v019004\DS135611 | dds1356v019004 | N/A | N/A | N/A | *Sterling* |
| IST | dss1356v019309\DS135611 | dss1356v019309 | N/A | N/A | N/A | *Sterling* |
| UAT | dus1356av018811\DS135611 | dus1356av018811 | AG_DWJG1356L01 | DWJG1356L01.ent.wfb.bank.corp,11001 | N/A | *Sterling* |
| PROD/BCP | dum1356av027909\UM1356A1 | dum1356av027909 | AG_DWP1356A1 | DWPG1356L01.ent.wfb.bank.corp,11001 | N/A | *Manassas* |
| PROD/BCP | dps1356av044101\PS1356A1 | dps1356av044101 | AG_DWP1356A1 | DWPG1356L01 | N/A | *Sterling* |
| PROD/BCP | dpm1356av049032\PM1356A1 | dpm1356av049032 | DWP1356L01 | DWPG1356L01 | N/A | *Manassas* |
| PROD/BCP | dpr1356av042851\PR1356A1 | dpr1356av042851 | — | — | — | *Lewisville* |
| PROD/BCP | dpd1356av010277\PD1356A1 | dpd1356av010277 | — | — | — | *Garland* |

*Note:* Replace any entry that differs from the grid with the exact value from your inventory.

h3. A.2 Detailed Steps (Runbook)
# *Onboard Request* → Create intake (SLA/RTO/RPO, DB sizes, contacts).
# *Servers Build* → Provision SQL 2022 (DEV/IST/UAT/PROD), storage and networking.
# *Servers Validation* → Patching, collation, instance config, TLS/certs, firewall, connectivity.
# *Logins Synchronization* → Logins/users/permissions; fix orphaned users.
# *AG Creation* → Multi-DC AG; PD1↔PF1 (Virginia) sync, PM1↔PS1 (Texas) sync; cross-site async.
# *Database Restore* → Full + diffs + logs; post-restore objects (jobs, links, synonyms).
# *AMA Workflows* → Automate replica role swap/switchover; validate listener.
# *Observability Onboarding* → AppDynamics & Grafana dashboards/alerts.
# *Liquibase + Harness* → CI/CD for schema changes; env vars & approvals.
# *Files & Streams Sync* → Heritage↔NGDC pipelines for files (NDM/Robocopy/SnapMirror) and streams (Kafka where applicable).
# *CNAME Updates* → DEV/IST/UAT DB listeners.
# *Connection Strings* → Update UI + ETL in DEV/IST/UAT; smoke tests.
# *Cutovers* → DEV → IST → UAT; then PROD parallel run → final cutover.

h3. A.3 Read-Only Routing (Prod AG)
*Primary in Virginia (PD1/PF1)* → route: local sync partner → Texas async replicas.  
*Primary in Texas (PM1/PS1)* → route: local sync partner → Virginia async replicas.

h3. A.4 Checklists (per environment)
- [ ] Backups validated and restores tested
- [ ] AG healthy; automatic seeding complete
- [ ] Jobs migrated & disabled on heritage post-cutover
- [ ] App smoke tests green; AppD baseline captured
- [ ] DR failover test scheduled/recorded
{expand}

----

{expand:title=Component B — SSIS Migration}
h3. B.1 Scope & Inventory
|| Project || Source Instance || Target Instance (SSISDB 2022) || Deployed? || Owner || Status ||
| <proj> | <2017 server> | <2022 server> | Yes/No | <name> | {status:in-progress} |

h3. B.2 Steps
# Extract package inventory; remove unused.
# Update *Connection Managers* (new listeners/CNAMEs, credentials, encryption).
# Migrate to *SSISDB* on SQL 2022; create *Environments* and *References*.
# Configure Agent proxies/creds; deploy via *Harness* pipeline.
# Functional tests in DEV → IST; performance & concurrency tests in UAT.
# Switch Autosys/SQL Agent schedules to NGDC; decommission heritage jobs.

h3. B.3 Validation
* Execution logs clean, expected durations met
* Data parity checks with heritage
* AppDynamics metrics stable/improved
{expand}

----

{expand:title=Component C — NAS Migration}
h3. C.1 Inventory
|| Share/Path || Size || Source NAS || Target NAS || Consumer App || Owner || Cutover Window || Status ||
| <\\old\path> | <size> | <name> | <name> | <app> | <owner> | <date/time> | {status:planned} |

h3. C.2 Steps
# Discovery (paths, perms, SMB/NFS, consumers).
# Baseline copy (SnapMirror/robocopy) → incremental syncs.
# Permissions & service accounts review; update mounts on app/batch hosts.
# Final delta cut + validation (MD5/file count/last-write timestamps).
# Update configs & documentation; disable heritage exports.

h3. C.3 Validation
* File counts/hash spot checks
* App read/write tests
{expand}

----

{expand:title=Component D — Autosys Migration}
h3. D.1 Inventory
|| Job || Type || Schedule || Dependencies || Owner || Status ||
| <job> | Box/Command/FileWatcher | <cron/cal> | <precedence> | <name> | {status:planned} |

h3. D.2 Steps
# Export JIL from heritage; normalize calendars/machines/queues.
# Map DB, SSIS, file paths to NGDC endpoints.
# DEV/IST dry-run; UAT parallel run with business signoff.
# PROD: freeze window, migrate, lift hold, and monitor.
{expand}

----

{expand:title=Component E — NDM Migration}
h3. E.1 Inventory
|| Flow || Partner/Node || Protocol/Port || Volume || Schedule || Owner || Status ||
| <flow> | <partner> | <proto/port> | <GB/day> | <cron> | <name> | {status:planned} |

h3. E.2 Steps
# Register processes/PNODE/SNODE on NGDC; certs/keys; firewall rules.
# Create new Process/Copy steps; test DEV/IST with checksums.
# UAT parallel run; throughput SLA verification.
# PROD cutover; disable heritage and archive scripts.
{expand}

----

h2. Risks & Mitigations
|| Risk || Impact || Mitigation ||
| Cross-site latency for reads | User-perceived slowness | Prefer local sync in read routing; pin analytics to RO listener |
| Package connection drift | ETL failures | Centralize secrets; env parameters; pre-cutover validation |
| NAS final delta overruns | Extended outage | Multiple incrementals; widen freeze window |
| Autosys dependency gaps | Job failures | End-to-end rehearsal in UAT; peer review of JIL |
| NDM certificates/firewall | Transfer failures | Early cert exchange; pre-approved firewall changes |

h2. Approvals
* Database: {status:in-progress}
* SSIS: {status:planned}
* NAS: {status:planned}
* Autosys: {status:planned}
* NDM: {status:planned}

h2. Change Log / AVI Updates
* Weekly AVI summary posted here; link Jira QGJK-34xxx items.


